"""
LLM ê¸°ë°˜ Review Agent

Geminië¥¼ ì‚¬ìš©í•œ ê³ ë„ì˜ ë¬¸ì„œ ë¦¬ë·°
"""
from typing import Optional
from dataclasses import dataclass
from pathlib import Path
import subprocess
import json


@dataclass
class ReviewResult:
    """ë¦¬ë·° ê²°ê³¼"""
    approved: bool
    comments: str
    score: float  # 0.0 ~ 1.0
    suggestions: list[str]  # ê°œì„  ì œì•ˆ
    issues: list[str]  # ë°œê²¬ëœ ë¬¸ì œ
    
    @property
    def status(self) -> str:
        return "APPROVED" if self.approved else "REJECTED"


class LLMReviewAgent:
    """LLM ê¸°ë°˜ Review Agent (Gemini ì‚¬ìš©)"""
    
    def __init__(self, use_llm: bool = True, approval_threshold: float = 0.7):
        """
        Args:
            use_llm: LLM ì‚¬ìš© ì—¬ë¶€ (Falseë©´ Mock ëª¨ë“œ)
            approval_threshold: ìŠ¹ì¸ ê¸°ì¤€ ì ìˆ˜
        """
        self.use_llm = use_llm
        self.approval_threshold = approval_threshold
        self.gemini_available = self._check_gemini_cli()
        
        if use_llm and not self.gemini_available:
            print("âš ï¸ Gemini CLI ì—†ìŒ - Mock ëª¨ë“œë¡œ ì „í™˜")
            self.use_llm = False
    
    def _check_gemini_cli(self) -> bool:
        """Gemini CLI ì„¤ì¹˜ í™•ì¸"""
        try:
            result = subprocess.run(
                ["gemini", "--version"],
                capture_output=True,
                timeout=5
            )
            return result.returncode == 0
        except:
            return False
    
    def review_spec(self, content: str, issue_title: str, issue_body: str = "") -> ReviewResult:
        """
        Spec ë¬¸ì„œ ë¦¬ë·°
        
        Args:
            content: Spec ë‚´ìš©
            issue_title: Issue ì œëª©
            issue_body: Issue ë³¸ë¬¸ (ì„ íƒ)
            
        Returns:
            ReviewResult
        """
        from utils.logger import review_logger
        
        review_logger.info(f"ğŸ“‹ Spec ë¦¬ë·° ì‹œì‘: '{issue_title}'")
        
        if self.use_llm and self.gemini_available:
            review_logger.info("  ğŸ¤– Gemini LLMìœ¼ë¡œ ê³ ê¸‰ ë¦¬ë·° ìˆ˜í–‰...")
            return self._llm_review_spec(content, issue_title, issue_body)
        else:
            review_logger.info("  ğŸ“ Mock ëª¨ë“œë¡œ ê¸°ë³¸ ê²€ì¦ ìˆ˜í–‰...")
            return self._mock_review_spec(content, issue_title)
    
    def _llm_review_spec(self, content: str, issue_title: str, issue_body: str) -> ReviewResult:
        """Gemini LLMìœ¼ë¡œ Spec ë¦¬ë·°"""
        from utils.logger import review_logger
        
        # Gemini í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""ë‹¹ì‹ ì€ ìˆ™ë ¨ëœ ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ Feature Specification ë¬¸ì„œë¥¼ ê²€í† í•˜ê³  ìƒì„¸í•œ ë¦¬ë·°ë¥¼ ì œê³µí•˜ì„¸ìš”.

## ì›ë³¸ Issue
ì œëª©: {issue_title}
ë‚´ìš©:
{issue_body if issue_body else "N/A"}

## ì‘ì„±ëœ Spec
{content}

## ê²€í†  í•­ëª©
1. **ì™„ì „ì„±**: ëª¨ë“  í•„ìˆ˜ ì„¹ì…˜ì´ ìˆëŠ”ê°€? (User Stories, Requirements, Success Criteria)
2. **ëª…í™•ì„±**: ìš”êµ¬ì‚¬í•­ì´ êµ¬ì²´ì ì´ê³  ëª¨í˜¸í•˜ì§€ ì•Šì€ê°€?
3. **í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ì„±**: Acceptance Criteriaê°€ ì¸¡ì • ê°€ëŠ¥í•œê°€?
4. **ì¼ê´€ì„±**: Issueì˜ ìš”êµ¬ì‚¬í•­ê³¼ Specì´ ì¼ì¹˜í•˜ëŠ”ê°€?
5. **í’ˆì§ˆ**: ì „ë¬¸ì ì´ê³  êµ¬ì¡°í™”ë˜ì–´ ìˆëŠ”ê°€?

## ì¶œë ¥ í˜•ì‹ (JSON)
{{
    "score": 0.85,  // 0.0 ~ 1.0
    "approved": true,  // score >= 0.7
    "summary": "ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•œ Specì…ë‹ˆë‹¤.",
    "issues": [
        "FR-002ê°€ ë„ˆë¬´ ëª¨í˜¸í•©ë‹ˆë‹¤",
        "Success Criteriaì— ì¸¡ì • ë°©ë²•ì´ ì—†ìŠµë‹ˆë‹¤"
    ],
    "suggestions": [
        "FR-002ì— êµ¬ì²´ì ì¸ ì‘ë‹µ ì‹œê°„ ê¸°ì¤€ ì¶”ê°€",
        "SC-001ì— ì¸¡ì • ë„êµ¬ ëª…ì‹œ"
    ],
    "strengths": [
        "User Storyê°€ Given-When-Then í˜•ì‹ìœ¼ë¡œ ëª…í™•í•¨",
        "ìš”êµ¬ì‚¬í•­ì´ êµ¬ì²´ì ì„"
    ]
}}
"""
        
        try:
            # Gemini CLI í˜¸ì¶œ
            review_logger.debug("  Gemini CLI í˜¸ì¶œ ì¤‘...")
            result = subprocess.run(
                ["gemini", "chat", "--prompt", prompt],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode != 0:
                review_logger.warning(f"  Gemini ì˜¤ë¥˜: {result.stderr}")
                return self._mock_review_spec(content, issue_title)
            
            # JSON íŒŒì‹±
            output = result.stdout.strip()
            review_logger.debug(f"  Gemini ì‘ë‹µ ê¸¸ì´: {len(output)}ì")
            
            # JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
            if "```json" in output:
                output = output.split("```json")[1].split("```")[0].strip()
            elif "```" in output:
                output = output.split("```")[1].split("```")[0].strip()
            
            data = json.loads(output)
            
            score = float(data.get("score", 0.5))
            approved = data.get("approved", score >= self.approval_threshold)
            issues = data.get("issues", [])
            suggestions = data.get("suggestions", [])
            strengths = data.get("strengths", [])
            
            review_logger.info(f"  Gemini ë¦¬ë·° ì™„ë£Œ - ì ìˆ˜: {score:.2f}")
            review_logger.debug(f"  ë°œê²¬ëœ ì´ìŠˆ: {len(issues)}ê°œ")
            review_logger.debug(f"  ê°œì„  ì œì•ˆ: {len(suggestions)}ê°œ")
            
            # ì½”ë©˜íŠ¸ ìƒì„±
            comments = f"""Gemini LLM ë¦¬ë·° ê²°ê³¼:

ì ìˆ˜: {score:.2f}/1.0
ìƒíƒœ: {'âœ… ìŠ¹ì¸' if approved else 'âŒ ê±°ë¶€'}

{data.get('summary', '')}

"""
            if strengths:
                comments += "\n**ê°•ì **:\n"
                for s in strengths:
                    comments += f"  âœ“ {s}\n"
            
            if issues:
                comments += "\n**ë°œê²¬ëœ ë¬¸ì œ**:\n"
                for i in issues:
                    comments += f"  âš ï¸ {i}\n"
            
            if suggestions:
                comments += "\n**ê°œì„  ì œì•ˆ**:\n"
                for s in suggestions:
                    comments += f"  ğŸ’¡ {s}\n"
            
            return ReviewResult(
                approved=approved,
                score=score,
                comments=comments,
                suggestions=suggestions,
                issues=issues
            )
            
        except Exception as e:
            review_logger.error(f"  Gemini ë¦¬ë·° ì˜¤ë¥˜: {e}")
            return self._mock_review_spec(content, issue_title)
    
    def _mock_review_spec(self, content: str, issue_title: str) -> ReviewResult:
        """Mock ëª¨ë“œ Spec ë¦¬ë·° (í‚¤ì›Œë“œ ì²´í¬)"""
        from utils.logger import review_logger
        
        review_logger.debug("  ê²€ì¦ í•­ëª© ì²´í¬...")
        
        checks = {
            'has_user_stories': '## User Scenarios' in content or 'User Story' in content,
            'has_requirements': 'Requirements' in content or 'Functional Requirements' in content,
            'has_success_criteria': 'Success Criteria' in content,
            'min_length': len(content) > 500
        }
        
        issues = []
        suggestions = []
        
        for name, passed in checks.items():
            review_logger.debug(f"  [{name}]: {'âœ“' if passed else 'âœ—'}")
            if not passed:
                if name == 'has_user_stories':
                    issues.append("User Stories ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤")
                    suggestions.append("User Storyë¥¼ Given-When-Then í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•˜ì„¸ìš”")
                elif name == 'has_requirements':
                    issues.append("Requirements ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤")
                    suggestions.append("Functional Requirementsë¥¼ FR-001 í˜•ì‹ìœ¼ë¡œ ì¶”ê°€í•˜ì„¸ìš”")
                elif name == 'has_success_criteria':
                    issues.append("Success Criteria ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤")
                    suggestions.append("ì¸¡ì • ê°€ëŠ¥í•œ ì„±ê³µ ê¸°ì¤€ì„ ì¶”ê°€í•˜ì„¸ìš”")
                elif name == 'min_length':
                    issues.append(f"ë¬¸ì„œê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ ({len(content)}ì)")
                    suggestions.append("ë” ìƒì„¸í•œ ì„¤ëª…ì„ ì¶”ê°€í•˜ì„¸ìš”")
        
        score = sum(checks.values()) / len(checks)
        approved = score >= self.approval_threshold
        
        review_logger.info(f"  ì´ì : {score:.2f}/1.0")
        
        comments = f"""Mock ë¦¬ë·° ê²°ê³¼:

ì ìˆ˜: {score:.2f}/1.0
ìƒíƒœ: {'âœ… ìŠ¹ì¸' if approved else 'âŒ ê±°ë¶€'}

ê²€ì¦ í•­ëª©: {sum(checks.values())}/{len(checks)} í†µê³¼
"""
        
        if issues:
            comments += "\n**ë°œê²¬ëœ ë¬¸ì œ**:\n"
            for i in issues:
                comments += f"  âš ï¸ {i}\n"
        
        if suggestions:
            comments += "\n**ê°œì„  ì œì•ˆ**:\n"
            for s in suggestions:
                comments += f"  ğŸ’¡ {s}\n"
        
        return ReviewResult(
            approved=approved,
            score=score,
            comments=comments,
            suggestions=suggestions,
            issues=issues
        )
